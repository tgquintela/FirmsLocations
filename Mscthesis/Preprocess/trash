
### 2015-10-29 ## Density assignation
###############################################################################
###############################################################################
################################# ProcessClass ################################
###############################################################################
class DensityAssign_Process(Processer):
    """Class which assigns a density value given a spatial point distribution
    of features.
    """

    ### Class parameters
    ## Process descriptors
    time_expended = 0.  # Time expended along the process
    n_procs = 0  # Number of cpu used in parallelization (0 no parallel)
    proc_name = "Density assignation process"  # Name of the process
    proc_desc = """Assignation of a quantity to a point given spatial density
    distribution."""
    ## Logger info
    lim_rows = 0  # Lim of rows done in a bunch. For matrix comp or information
    logfile = None  # Log file
    ## Bool options
    bool_inform = False  # Give information of the process
    bool_matrix = False  # compute matrix

    subproc_desc = []
    t_expended_subproc = []

    def __init__(self, logfile, retriever, lim_rows=0, n_procs=0,
                 proc_name=""):
        "Instantiation of a density assignation process class."

        # Logfile
        self.logfile = logfile
        ## Retriever
        self.retriever = retriever

        # Other parameters
        self.lim_rows = lim_rows
        self.bool_inform = True if self.lim_rows != 0 else False
        self.n_procs = n_procs
        if proc_name != "":
            self.proc_name = proc_name
        self.proc_desc = "Computation %s with %s"

    def compute_density(self, locs, data, datavars, info_ret, params):
        """Compute density of the locations locs from a spatial distribution
        of features given in data.
        """

        d = compute_population_data(locs, data, datavars, self.retriever,
                                    info_ret, params)
        return d


###############################################################################
############################## Auxiliary functions ############################
###############################################################################
def compute_population_data(locs, data, datavars, retriever, info_ret, params):
    """Function to compute the correspondant density data to each point in locs
    given the spatial distribution of features given in data.
    """

    ## 0. Computation of initial variables
    locs = np.array(locs)

    locs_data = np.array(data[datavars['loc_vars']])
    pop_data = np.array(data[datavars['feat_vars']])

    # Defining the retriever
    retriever = retriever(locs_data)

    ## 1. Computation of assignation to point
    dens_assignation = general_density_assignation(locs, retriever, info_ret,
                                                   pop_data, **params)

    return dens_assignation


### 2015-10-29
def density_assignation_f(weights, values):
    """Density function decided. Varibale values has 3dim: feature value,
    density and area.
    """
    ## Only use population data
    dens_assign = np.dot(values[:, 0], weights)
    return dens_assign



def compute_aggregate_counts_grid(locs_grid, feat_arr, reindices):
    "Define the aggretriever information."
    #### TODEPRECATE
    # locs_grid, reindices, feat_arr
    from itertools import product
    u1, u2 = np.unique(locs_grid[:, 0]), np.unique(locs_grid[:, 1])
    N_calc = reindices.shape[1]
    n_vals = []
    for i in range(feat_arr.shape[1]):
        n_vals.append(np.unique(feat_arr[:, i]).shape[0])
    agglocs, aggfeatures = [], []
    for p in product(u1, u2):
        ## Function to check if it is all equal
        logi = locs_grid == p
        logi = np.logical_and(logi[:, 0], logi[:, 1])
        if logi.sum() > 0:
            ## Computation of counts for each permutation in a given cell p
            auxM = []
            for j in range(N_calc):
                idxs = reindices[:, j]
                aux = computation_aggregate_collapse_i(feat_arr[idxs[logi], :],
                                                       n_vals)
                aux = aux.reshape(aux.shape[0], 1)
                auxM.append(aux)
            ## Prepare outputs
            agglocs.append(p)
            auxM = np.concatenate(auxM, axis=1)
            auxM = auxM.reshape(auxM.shape[0], auxM.shape[1], 1)
            aggfeatures.append(auxM)
    ## Format output
    aggfeatures = np.concatenate(aggfeatures, axis=2)
    aggfeatures = np.swapaxes(np.concatenate(aggfeatures, axis=2), 2, 1)
    agglocs = np.array(agglocs)
    return agglocs, aggfeatures



class Aggregator():
    "Aggregate or read aggregate information."

    def __init__(self, filepath=None, typevars=None, vals=None):
        if filepath is None:
            typevars = format_typevars(typevars)
            self.vals = vals
            self.typevars = typevars
            self.bool_read_agg = False
        else:
            self.bool_read_agg = True
            typevars = format_typevars(typevars)
            self.typevars = typevars

    def retrieve_aggregation(self, df=None, reindices=None):
        "Main function for retrieving aggregation."
        if self.bool_read_agg:
            # TODO: Function to read file
            filepath, typevars = self.filepath, self.typevars
            agglocs, aggfeatures = read_aggregation(filepath, typevars)
        else:
            ## Correct inputs
            locs = df[self.typevars['loc_vars']].as_matrix()
            feat_arr = df[self.typevars['feat_vars']].as_matrix()
            if self.typevars['agg_var'] is None:
                agg_arr = None
            else:
                agg_arr = df[self.typevars['agg_var']].as_matrix()
            if reindices is None:
                N_t = locs.shape[0]
                reindices = np.array(range(N_t)).reshape((N_t, 1))
            if len(feat_arr.shape) == 1:
                feat_arr = feat_arr.reshape(feat_arr.shape[0], 1)
            ## Compute agglocs and aggfeatures
            agglocs, aggfeatures = create_aggregation(locs, agg_arr, feat_arr,
                                                      reindices, self.vals,
                                                      self.typevars)
        ## Format output
        agglocs = np.array(agglocs)
        ndim, N_t = len(agglocs.shape), agglocs.shape[0]
        agglocs = agglocs if ndim > 1 else agglocs.reshape((N_t, 1))
        return agglocs, aggfeatures



#def create_aggregation(locs, agg_arr, feat_arr, reindices):
#    if agg_arr is None:
#        locs, agg_desc = compute_aggregate_counts_grid(locs, feat_arr,
#                                                       reindices)
#    else:
#        agg_var = 'agg'
#        loc_vars = [chr(97+i) for i in range(locs.shape[1])]
#        feat_vars = [str(i) for i in range(feat_arr.shape[1])]
#        variables = loc_vars + [agg_var] + feat_vars
#        df = pd.DataFrame([locs, agg_arr, feat_arr], columns=variables)
#        agg_desc, axis, locs = compute_aggregate_counts(df, agg_var, loc_vars,
#                                                        feat_vars, reindices)
#    return locs, agg_desc


###__init__
class Aggregator():
    "Aggregate or read aggregate information."

    def __init__(self, typevars, filepath=None):
        self.typevars = typevars
        if filepath is None:
            self.bool_read_agg = False
        else:
            self.bool_read_agg = True

    def retrieve_aggregation(self, df=None, reindices=None):
        "Main function for retrieving aggregation."
        if self.bool_read_agg:
            typevars, filepath = self.typevars, self.filepath
            aggfeatures, agglocs = read_aggregation(typevars, filepath)
        else:
            typevars = self.typevars
            aggfeatures, agglocs = create_aggregation(df, typevars, reindices)
        ## Format output
        agglocs = np.array(agglocs)
        ndim, N_t = len(agglocs.shape), agglocs.shape[0]
        agglocs = agglocs if ndim > 1 else agglocs.reshape((N_t, 1))
        return agglocs, aggfeatures


